{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih4VxVulNyQw"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import vgg16_bn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to create dataframe\n",
        "def create_dataframe(data_directory):\n",
        "    images_paths = []\n",
        "    masks_paths = glob(f'{data_directory}/*/*_mask*')\n",
        "\n",
        "    for mask_path in masks_paths:\n",
        "        images_paths.append(mask_path.replace('_mask', ''))\n",
        "\n",
        "    dataframe = pd.DataFrame(data={'images_paths': images_paths, 'masks_paths': masks_paths})\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "# Function to split dataframe into train, valid, test\n",
        "def split_dataframe(dataframe):\n",
        "    # Create train_dataframe\n",
        "    train_dataframe, dummy_dataframe = train_test_split(dataframe, train_size=0.8)\n",
        "\n",
        "    # Create valid_dataframe and test_dataframe\n",
        "    valid_dataframe, test_dataframe = train_test_split(dummy_dataframe, train_size=0.5)\n",
        "\n",
        "    return train_dataframe, valid_dataframe, test_dataframe\n",
        "\n",
        "data_path = \"/content/lgg-mri-segmentation/kaggle_3m\"\n",
        "df = create_dataframe(data_path)\n",
        "train_df, val_df, test_df = split_dataframe(df)\n",
        "\n",
        "# Display sample from the training data\n",
        "print('Train\\t', train_df.shape, '\\nVal\\t', val_df.shape, '\\nTest\\t', test_df.shape)\n",
        "\n",
        "# Load and display sample image and mask\n",
        "image = cv2.imread(train_df.iloc[0, 0]) / 255.0\n",
        "mask = cv2.imread(train_df.iloc[0, 1]) / 255.0\n",
        "mask = np.where(mask >= 0.5, 1., 0.)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.title('Image' + str(image.shape))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask)\n",
        "plt.title('Mask' + str(mask.shape))\n",
        "plt.show()\n",
        "\n",
        "# Define the BrainMRI dataset class\n",
        "class BrainMRIDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, transform=None, mask_transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.df.iloc[idx, 0]) / 255.0\n",
        "        mask = cv2.imread(self.df.iloc[idx, 1]) / 255.0\n",
        "        mask = np.where(mask >= 0.5, 1., 0.)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((256, 256))\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_data = BrainMRIDataset(train_df, transform=transform, mask_transform=transform)\n",
        "val_data = BrainMRIDataset(val_df, transform=transform, mask_transform=transform)\n",
        "test_data = BrainMRIDataset(test_df, transform=transform, mask_transform=transform)\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Display batch information\n",
        "print('Training batches\\t', len(train_dataloader))\n",
        "print('Validation batches\\t', len(val_dataloader))\n",
        "print('Test batches\\t\\t', len(test_dataloader))\n",
        "\n",
        "# Count the number of training and validation images\n",
        "num_train_images = len(train_df)\n",
        "num_val_images = len(val_df)\n",
        "\n",
        "print(f'Number of Training Images: {num_train_images}')\n",
        "print(f'Number of Validation Images: {num_val_images}')\n",
        "\n",
        "# Evaluate the model on the test set and calculate accuracy\n",
        "model.eval()\n",
        "total_test_iou = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images, labels = images.to(device).float(), labels.to(device).float()\n",
        "        predictions = model(images)\n",
        "        iou = IOU(labels, predictions)\n",
        "        total_test_iou += iou.item()\n",
        "\n",
        "    test_accuracy = total_test_iou / len(test_dataloader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Display sample from dataloader\n",
        "img_sample, msk_sample = next(iter(val_dataloader))\n",
        "print(img_sample.shape, '\\t', img_sample.dtype)\n",
        "print(msk_sample.shape, '\\t', msk_sample.dtype)\n",
        "\n",
        "fig, axs = plt.subplots(2, 6, figsize=(20, 10))\n",
        "for i in range(6):\n",
        "    axs[0, i].imshow(img_sample[i].permute(1, 2, 0))\n",
        "    axs[0, i].set_title(\"Image\")\n",
        "\n",
        "    axs[1, i].imshow(msk_sample[i].permute(1, 2, 0))\n",
        "    axs[1, i].set_title(\"Mask\")\n",
        "fig.suptitle('Data Sample')\n",
        "fig.tight_layout()\n",
        "fig.show()\n"
      ]
    }
  ]
}